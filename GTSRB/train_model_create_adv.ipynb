{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "from numpy import asarray\n",
    "from numpy import load\n",
    "import random\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, channels = 48, 48, 3\n",
    "num_classes = 43\n",
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (img_rows, img_cols))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "\n",
    "root_dir = 'GTSRB_dataset/Final_Training/Images/'\n",
    "imgs = []\n",
    "labels = []\n",
    "#load train dataset\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    img = preprocess_img(io.imread(img_path))\n",
    "    label = get_class(img_path)\n",
    "    imgs.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "x_train = np.array(imgs, dtype='float32')\n",
    "# Make one hot targets\n",
    "y_train = np.eye(num_classes, dtype='uint8')[labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('GT-final_test.csv', sep=';')\n",
    "\n",
    "# Load test dataset\n",
    "x_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    img_path = os.path.join('GTSRB_dataset/Final_Test/Images/', file_name)\n",
    "    x_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], img_rows, img_cols, channels))\n",
    "x_test = x_test.reshape((x_test.shape[0], img_rows, img_cols, channels))\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(img_rows, img_cols, channels), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39209 samples, validate on 12630 samples\n",
      "Epoch 1/30\n",
      "39209/39209 [==============================] - 101s 3ms/sample - loss: 3.5314 - accuracy: 0.0619 - val_loss: 3.4434 - val_accuracy: 0.0914\n",
      "Epoch 2/30\n",
      "39209/39209 [==============================] - 100s 3ms/sample - loss: 3.2183 - accuracy: 0.1384 - val_loss: 2.7479 - val_accuracy: 0.2271\n",
      "Epoch 3/30\n",
      "39209/39209 [==============================] - 100s 3ms/sample - loss: 2.5981 - accuracy: 0.2521 - val_loss: 2.2280 - val_accuracy: 0.3302\n",
      "Epoch 4/30\n",
      "39209/39209 [==============================] - 100s 3ms/sample - loss: 2.1217 - accuracy: 0.3533 - val_loss: 1.8999 - val_accuracy: 0.4008\n",
      "Epoch 5/30\n",
      "39209/39209 [==============================] - 100s 3ms/sample - loss: 1.7718 - accuracy: 0.4350 - val_loss: 1.6083 - val_accuracy: 0.5004\n",
      "Epoch 6/30\n",
      "39209/39209 [==============================] - 98s 3ms/sample - loss: 1.4721 - accuracy: 0.5228 - val_loss: 1.3388 - val_accuracy: 0.5788\n",
      "Epoch 7/30\n",
      "39209/39209 [==============================] - 74s 2ms/sample - loss: 1.1928 - accuracy: 0.6138 - val_loss: 1.0634 - val_accuracy: 0.6712\n",
      "Epoch 8/30\n",
      "39209/39209 [==============================] - 74s 2ms/sample - loss: 0.9072 - accuracy: 0.7093 - val_loss: 0.8787 - val_accuracy: 0.7253\n",
      "Epoch 9/30\n",
      "39209/39209 [==============================] - 74s 2ms/sample - loss: 0.6759 - accuracy: 0.7834 - val_loss: 0.6435 - val_accuracy: 0.8063\n",
      "Epoch 10/30\n",
      "39209/39209 [==============================] - 72s 2ms/sample - loss: 0.5159 - accuracy: 0.8352 - val_loss: 0.5378 - val_accuracy: 0.8389\n",
      "Epoch 11/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.4009 - accuracy: 0.8711 - val_loss: 0.4587 - val_accuracy: 0.8618\n",
      "Epoch 12/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.3216 - accuracy: 0.8952 - val_loss: 0.4361 - val_accuracy: 0.8763\n",
      "Epoch 13/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.2623 - accuracy: 0.9149 - val_loss: 0.3813 - val_accuracy: 0.8883\n",
      "Epoch 14/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.2277 - accuracy: 0.9274 - val_loss: 0.3515 - val_accuracy: 0.8988\n",
      "Epoch 15/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.1945 - accuracy: 0.9367 - val_loss: 0.3398 - val_accuracy: 0.9078\n",
      "Epoch 16/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1693 - accuracy: 0.9443 - val_loss: 0.3464 - val_accuracy: 0.9095\n",
      "Epoch 17/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1513 - accuracy: 0.9512 - val_loss: 0.3269 - val_accuracy: 0.9131\n",
      "Epoch 18/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1359 - accuracy: 0.9560 - val_loss: 0.3211 - val_accuracy: 0.9188\n",
      "Epoch 19/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1201 - accuracy: 0.9605 - val_loss: 0.3187 - val_accuracy: 0.9162\n",
      "Epoch 20/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.1092 - accuracy: 0.9647 - val_loss: 0.3178 - val_accuracy: 0.9234\n",
      "Epoch 21/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1018 - accuracy: 0.9666 - val_loss: 0.3072 - val_accuracy: 0.9259\n",
      "Epoch 22/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.0923 - accuracy: 0.9700 - val_loss: 0.3358 - val_accuracy: 0.9224\n",
      "Epoch 23/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0874 - accuracy: 0.9712 - val_loss: 0.2915 - val_accuracy: 0.9295\n",
      "Epoch 24/30\n",
      "39209/39209 [==============================] - 69s 2ms/sample - loss: 0.0797 - accuracy: 0.9744 - val_loss: 0.3254 - val_accuracy: 0.9232\n",
      "Epoch 25/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0743 - accuracy: 0.9759 - val_loss: 0.3110 - val_accuracy: 0.9284\n",
      "Epoch 26/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.0665 - accuracy: 0.9781 - val_loss: 0.3231 - val_accuracy: 0.9303\n",
      "Epoch 27/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0652 - accuracy: 0.9786 - val_loss: 0.3187 - val_accuracy: 0.9306\n",
      "Epoch 28/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0606 - accuracy: 0.9803 - val_loss: 0.3392 - val_accuracy: 0.9232\n",
      "Epoch 29/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0580 - accuracy: 0.9811 - val_loss: 0.3389 - val_accuracy: 0.9248\n",
      "Epoch 30/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.3148 - val_accuracy: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9322873630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39209 samples, validate on 12630 samples\n",
      "Epoch 1/30\n",
      "39209/39209 [==============================] - 72s 2ms/sample - loss: 3.5242 - accuracy: 0.0601 - val_loss: 3.4565 - val_accuracy: 0.1010\n",
      "Epoch 2/30\n",
      "39209/39209 [==============================] - 72s 2ms/sample - loss: 3.2312 - accuracy: 0.1359 - val_loss: 2.7677 - val_accuracy: 0.2282\n",
      "Epoch 3/30\n",
      "39209/39209 [==============================] - 78s 2ms/sample - loss: 2.6068 - accuracy: 0.2521 - val_loss: 2.2761 - val_accuracy: 0.3268\n",
      "Epoch 4/30\n",
      "39209/39209 [==============================] - 77s 2ms/sample - loss: 2.1391 - accuracy: 0.3482 - val_loss: 1.8744 - val_accuracy: 0.4224\n",
      "Epoch 5/30\n",
      "39209/39209 [==============================] - 73s 2ms/sample - loss: 1.7611 - accuracy: 0.4398 - val_loss: 1.5671 - val_accuracy: 0.5019\n",
      "Epoch 6/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 1.4192 - accuracy: 0.5438 - val_loss: 1.2602 - val_accuracy: 0.6028\n",
      "Epoch 7/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 1.0747 - accuracy: 0.6484 - val_loss: 0.9029 - val_accuracy: 0.7216\n",
      "Epoch 8/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.7724 - accuracy: 0.7463 - val_loss: 0.7415 - val_accuracy: 0.7699\n",
      "Epoch 9/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.5761 - accuracy: 0.8066 - val_loss: 0.6079 - val_accuracy: 0.8203\n",
      "Epoch 10/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.4374 - accuracy: 0.8546 - val_loss: 0.4764 - val_accuracy: 0.8621\n",
      "Epoch 11/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.3431 - accuracy: 0.8862 - val_loss: 0.4488 - val_accuracy: 0.8689\n",
      "Epoch 12/30\n",
      "39209/39209 [==============================] - 72s 2ms/sample - loss: 0.2815 - accuracy: 0.9073 - val_loss: 0.4152 - val_accuracy: 0.8793\n",
      "Epoch 13/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.2305 - accuracy: 0.9234 - val_loss: 0.3981 - val_accuracy: 0.8878\n",
      "Epoch 14/30\n",
      "39209/39209 [==============================] - 72s 2ms/sample - loss: 0.1962 - accuracy: 0.9358 - val_loss: 0.3479 - val_accuracy: 0.9019\n",
      "Epoch 15/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1711 - accuracy: 0.9432 - val_loss: 0.3709 - val_accuracy: 0.9003\n",
      "Epoch 16/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.1532 - accuracy: 0.9505 - val_loss: 0.3298 - val_accuracy: 0.9130\n",
      "Epoch 17/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.1355 - accuracy: 0.9550 - val_loss: 0.3386 - val_accuracy: 0.9109\n",
      "Epoch 18/30\n",
      "39209/39209 [==============================] - 70s 2ms/sample - loss: 0.1215 - accuracy: 0.9594 - val_loss: 0.3428 - val_accuracy: 0.9132\n",
      "Epoch 19/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.1126 - accuracy: 0.9622 - val_loss: 0.3175 - val_accuracy: 0.9178\n",
      "Epoch 20/30\n",
      "39209/39209 [==============================] - 72s 2ms/sample - loss: 0.0969 - accuracy: 0.9671 - val_loss: 0.3111 - val_accuracy: 0.9184\n",
      "Epoch 21/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0909 - accuracy: 0.9690 - val_loss: 0.3068 - val_accuracy: 0.9244\n",
      "Epoch 22/30\n",
      "39209/39209 [==============================] - 71s 2ms/sample - loss: 0.0831 - accuracy: 0.9725 - val_loss: 0.2960 - val_accuracy: 0.9221\n",
      "Epoch 23/30\n",
      "39209/39209 [==============================] - 50s 1ms/sample - loss: 0.0774 - accuracy: 0.9738 - val_loss: 0.3454 - val_accuracy: 0.9195\n",
      "Epoch 24/30\n",
      "39209/39209 [==============================] - 47s 1ms/sample - loss: 0.0740 - accuracy: 0.9750 - val_loss: 0.3096 - val_accuracy: 0.9278\n",
      "Epoch 25/30\n",
      "39209/39209 [==============================] - 47s 1ms/sample - loss: 0.0670 - accuracy: 0.9772 - val_loss: 0.3162 - val_accuracy: 0.9257\n",
      "Epoch 26/30\n",
      "39209/39209 [==============================] - 47s 1ms/sample - loss: 0.0632 - accuracy: 0.9790 - val_loss: 0.3044 - val_accuracy: 0.9280\n",
      "Epoch 27/30\n",
      "39209/39209 [==============================] - 48s 1ms/sample - loss: 0.0595 - accuracy: 0.9812 - val_loss: 0.3015 - val_accuracy: 0.9311\n",
      "Epoch 28/30\n",
      "39209/39209 [==============================] - 46s 1ms/sample - loss: 0.0543 - accuracy: 0.9821 - val_loss: 0.3369 - val_accuracy: 0.9243\n",
      "Epoch 29/30\n",
      "39209/39209 [==============================] - 47s 1ms/sample - loss: 0.0530 - accuracy: 0.9821 - val_loss: 0.3086 - val_accuracy: 0.9251\n",
      "Epoch 30/30\n",
      "39209/39209 [==============================] - 47s 1ms/sample - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.3071 - val_accuracy: 0.9280\n"
     ]
    }
   ],
   "source": [
    "m1=tf.keras.models.clone_model(model)\n",
    "lr = 0.001\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "m1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "m1.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(x_test, y_test))\n",
    "m1.save('final_model_clean.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy on regular images: 0.9364212\n",
      "Base loss on regular images: 0.3147545412508734\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Base accuracy on regular images:\", acc)\n",
    "print(\"Base loss on regular images:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_pattern(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(label, prediction)\n",
    "    \n",
    "    gradient = tape.gradient(loss, image)\n",
    "    \n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarials(batch_size):\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for batch in range(batch_size):\n",
    "            #N = random.randint(0, 100)\n",
    "\n",
    "            label = y_test[batch]\n",
    "            image = x_test[batch]\n",
    "            \n",
    "            perturbations = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), label).numpy()\n",
    "            \n",
    "            \n",
    "            epsilon = 0.3\n",
    "            adversarial = image + perturbations * epsilon\n",
    "            \n",
    "            x.append(adversarial)\n",
    "            y.append(y_test[batch])\n",
    "        \n",
    "        \n",
    "        x = np.asarray(x).reshape((batch_size, img_rows, img_cols, channels))\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adversarial_test, y_adversarial_test = next(generate_adversarials(12630))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy on regular images: 0.9364212\n",
      "Base loss on regular images: 0.3147545412508734\n",
      "Base accuracy on adversarial images: 0.30451307\n",
      "Base loss on adversarial images: 14.670813890005611\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Base accuracy on regular images:\", acc1)\n",
    "print(\"Base loss on regular images:\", loss1)\n",
    "loss2, acc2 = model.evaluate(x_adversarial_test, y_adversarial_test, verbose=0)\n",
    "print(\"Base accuracy on adversarial images:\",acc2)\n",
    "print('Base loss on adversarial images:', loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('adversarial_test_images',x_adversarial_test)\n",
    "save('adversarial_test_labels',y_adversarial_test)\n",
    "save('clean_test_images',x_test)\n",
    "save('clean_test_labels',y_test)\n",
    "model.save('final_model_adv.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
